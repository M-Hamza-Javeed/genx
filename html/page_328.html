<div id="page0" style="position:relative;width:540pt;height:648pt;background-color:white">
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:92pt;left:72pt"><b><span style="font-family:Helvetica,sans-serif;font-size:24.79pt">Chapter 12. Optimization</span></b></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:130pt;left:72pt"><span style="font-family:Times,serif;font-size:9.963pt">Premature optimization is the root of all evil.</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:142pt;left:72pt"><span style="font-family:Times,serif;font-size:9.963pt">--</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:154pt;left:72pt"><span style="font-family:Times,serif;font-size:9.963pt;color:#ff0000">&lt;author&gt;C.A. R.Hoare&lt;/author&gt;</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:176pt;left:72pt"><span style="font-family:Times,serif;font-size:9.963pt">This is going to be a very short chapter, because the main thing Unix experience teaches us about</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:188pt;left:72pt"><span style="font-family:Times,serif;font-size:9.963pt">optimizing for performance is how to know when not to do it. A secondary lesson is that the most</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:200pt;left:72pt"><span style="font-family:Times,serif;font-size:9.963pt">effective optimization tactics are usually things we do for other reasons, such as cleanness of design.</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:222pt;left:72pt"><b><span style="font-family:Helvetica,sans-serif;font-size:15.94pt">Don&#x2019;t Just Do Something, Stand There!</span></b></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:251pt;left:72pt"><span style="font-family:Times,serif;font-size:9.963pt">The most powerful optimization technique in any programmer&#x2019;s toolbox is to do nothing.</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:272pt;left:72pt"><span style="font-family:Times,serif;font-size:9.963pt">This very Zen advice is true for several reasons. One is the exponential effect of Moore&#x2019;s Law &#x2014;</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:284pt;left:72pt"><span style="font-family:Times,serif;font-size:9.963pt">the smartest, cheapest, and often</span><i><span style="font-family:Times,serif;font-size:9.963pt"> fastest</span></i><span style="font-family:Times,serif;font-size:9.963pt"> way to collect performance gains is to wait a few months</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:296pt;left:72pt"><span style="font-family:Times,serif;font-size:9.963pt">for your target hardware to become more capable. Given the cost ratio between hardware and</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:308pt;left:72pt"><span style="font-family:Times,serif;font-size:9.963pt">programmer time, there are almost always better things to do with your time than to optimize a</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:320pt;left:72pt"><span style="font-family:Times,serif;font-size:9.963pt">working system.</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:342pt;left:72pt"><span style="font-family:Times,serif;font-size:9.963pt">We can get mathematically speci&#xfb01;c about this.</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:342pt;left:270pt"><span style="font-family:Times,serif;font-size:9.963pt">It is almost never worth doing optimizations that</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:354pt;left:72pt"><span style="font-family:Times,serif;font-size:9.963pt">reduce resource use by merely a constant factor; it&#x2019;s smarter to concentrate effort on cases in which</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:362pt;left:72pt"><span style="font-family:Times,serif;font-size:9.963pt">you can reduce average-case running time or space use from O(</span><i><span style="font-family:Times,serif;font-size:9.963pt">n</span></i><sup><span style="font-family:Times,serif;font-size:6.974pt">2</span></sup><span style="font-family:Times,serif;font-size:9.963pt">) to O(</span><i><span style="font-family:Times,serif;font-size:9.963pt">n</span></i><span style="font-family:Times,serif;font-size:9.963pt">) or O(</span><i><span style="font-family:Times,serif;font-size:9.963pt">n</span></i><span style="font-family:Times,serif;font-size:9.963pt"> log</span><i><span style="font-family:Times,serif;font-size:9.963pt"> n</span></i><span style="font-family:Times,serif;font-size:9.963pt">),</span><sup><span style="font-family:Times,serif;font-size:6.273pt">112</span></sup><sup><span style="font-family:Times,serif;font-size:9.963pt"> </span></sup><span style="font-family:Times,serif;font-size:9.963pt">or</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:378pt;left:71pt"><span style="font-family:Times,serif;font-size:9.963pt">similarly reduce from a higher order. Linear performance gains tend to be rapidly swamped by</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:390pt;left:71pt"><span style="font-family:Times,serif;font-size:9.963pt">Moore&#x2019;s Law.</span><sup><span style="font-family:Times,serif;font-size:6.273pt">113</span></sup></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:408pt;left:72pt"><span style="font-family:Times,serif;font-size:5.018pt">112</span><span style="font-family:Times,serif;font-size:7.97pt">For readers unfamiliar with O notation, it is a way of indicating how the average running time of an algorithm changes with</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:417pt;left:72pt"><span style="font-family:Times,serif;font-size:7.97pt">the size of its inputs. An O(1) algorithm runs in constant time. An O(</span><i><span style="font-family:Times,serif;font-size:7.97pt">n</span></i><span style="font-family:Times,serif;font-size:7.97pt">) algorithm runs in a time that is predicted by</span><tt><span style="font-family:Courier,monospace;font-size:7.173pt"> A</span></tt><tt><i><span style="font-family:Courier,monospace;font-size:6.456pt">n</span></i></tt><tt><span style="font-family:Courier,monospace;font-size:7.173pt"> + C</span></tt><span style="font-family:Times,serif;font-size:7.97pt">,</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:427pt;left:72pt"><span style="font-family:Times,serif;font-size:7.97pt">where</span><tt><span style="font-family:Courier,monospace;font-size:7.173pt"> A</span></tt><span style="font-family:Times,serif;font-size:7.97pt"> is some unknown constant of proportionality and</span><tt><span style="font-family:Courier,monospace;font-size:7.173pt"> C</span></tt><span style="font-family:Times,serif;font-size:7.97pt"> is an unknown constant representing setup time. Linear search</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:434pt;left:72pt"><span style="font-family:Times,serif;font-size:7.97pt">of a list for a speci&#xfb01;ed value is O(</span><i><span style="font-family:Times,serif;font-size:7.97pt">n</span></i><span style="font-family:Times,serif;font-size:7.97pt">). An O(</span><i><span style="font-family:Times,serif;font-size:7.97pt">n</span></i><sup><span style="font-family:Times,serif;font-size:5.978pt">2</span></sup><span style="font-family:Times,serif;font-size:7.97pt">) algorithm runs in time</span><tt><span style="font-family:Courier,monospace;font-size:7.173pt"> A</span></tt><tt><i><span style="font-family:Courier,monospace;font-size:6.456pt">n</span></i></tt><sup><tt><span style="font-family:Courier,monospace;font-size:4.519pt">2</span></tt></sup><sup><span style="font-family:Times,serif;font-size:7.97pt"> </span></sup><span style="font-family:Times,serif;font-size:7.97pt">plus lower-order terms (which might be linear,</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:446pt;left:72pt"><span style="font-family:Times,serif;font-size:7.97pt">or logarithmic, of any other function lower than a quadratic). Checking a list for duplicate values (by the na&#xef;ve method, not</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:455pt;left:72pt"><span style="font-family:Times,serif;font-size:7.97pt">sorting it) is O(</span><i><span style="font-family:Times,serif;font-size:7.97pt">n</span></i><sup><span style="font-family:Times,serif;font-size:5.978pt">2</span></sup><span style="font-family:Times,serif;font-size:7.97pt">). Similarly, O(</span><i><span style="font-family:Times,serif;font-size:7.97pt">n</span></i><sup><span style="font-family:Times,serif;font-size:5.978pt">3</span></sup><span style="font-family:Times,serif;font-size:7.97pt">) algorithms have an average run time predicted by the cube of problem size; these tend</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:465pt;left:72pt"><span style="font-family:Times,serif;font-size:7.97pt">to be too slow for practical use. O(log</span><i><span style="font-family:Times,serif;font-size:7.97pt"> n</span></i><span style="font-family:Times,serif;font-size:7.97pt">) is typical of tree searches. Intelligent choice of algorithm can often reduce running</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:474pt;left:72pt"><span style="font-family:Times,serif;font-size:7.97pt">time from O(</span><i><span style="font-family:Times,serif;font-size:7.97pt">n</span></i><sup><span style="font-family:Times,serif;font-size:5.978pt">2</span></sup><span style="font-family:Times,serif;font-size:7.97pt">) to O(log</span><i><span style="font-family:Times,serif;font-size:7.97pt"> n</span></i><span style="font-family:Times,serif;font-size:7.97pt">). Sometimes when we are interested in predicting an algorithm&#x2019;s memory utilization, we may</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:483pt;left:72pt"><span style="font-family:Times,serif;font-size:7.97pt">notice that it varies as O(1) or O(</span><i><span style="font-family:Times,serif;font-size:7.97pt">n</span></i><span style="font-family:Times,serif;font-size:7.97pt">) or O(</span><i><span style="font-family:Times,serif;font-size:7.97pt">n</span></i><sup><span style="font-family:Times,serif;font-size:5.978pt">2</span></sup><span style="font-family:Times,serif;font-size:7.97pt">); in general, algorithms with O(</span><i><span style="font-family:Times,serif;font-size:7.97pt">n</span></i><sup><span style="font-family:Times,serif;font-size:5.978pt">2</span></sup><span style="font-family:Times,serif;font-size:7.97pt">) or higher memory utilization are not practical</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:494pt;left:72pt"><span style="font-family:Times,serif;font-size:7.97pt">either.</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:501pt;left:72pt"><span style="font-family:Times,serif;font-size:5.018pt">113</span><span style="font-family:Times,serif;font-size:7.97pt">The eighteen-month doubling time usually quoted for Moore&#x2019;s Law implies that you can collect a 26% performance gain</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:511pt;left:72pt"><span style="font-family:Times,serif;font-size:7.97pt">just by buying new hardware in six months.</span></p>
<p style="position:absolute;white-space:pre;margin:0;padding:0;top:581pt;left:262pt"><span style="font-family:Times,serif;font-size:9.963pt">327</span></p>
</div>
